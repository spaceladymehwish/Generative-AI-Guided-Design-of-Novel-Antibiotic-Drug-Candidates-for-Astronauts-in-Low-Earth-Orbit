{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TT4GsZ_Os3x"
      },
      "source": [
        "# **libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "AhcieIm2dRKh",
        "outputId": "0b726d9e-fb84-4583-c59c-3ed555126f40"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzHlnowvdRe7",
        "outputId": "59149385-2fe2-4531-9649-06e074c85c2a"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y pandas\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mVMO5B9bbkd",
        "outputId": "a81ec200-03ab-4cd2-b749-a977504c2b3f"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SHfEeH2VdeZT",
        "outputId": "23d70bb1-de67-4a21-d809-4823c29c5ab4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs, Descriptors, rdChemReactions\n",
        "from real_reactions import REAL_REACTIONS\n",
        "from torch import distributions\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit.Chem import Draw\n",
        "from PIL import Image  # Ensure it's from PIL\n",
        "\n",
        "##############################\n",
        "# 1. Property Predictor\n",
        "##############################\n",
        "\n",
        "def compute_rdkit_descriptors(mol):\n",
        "    from rdkit.Chem import Descriptors, rdMolDescriptors, Crippen, Lipinski, Fragments, EState, GraphDescriptors\n",
        "    try:\n",
        "        return np.array([\n",
        "            EState.MaxEStateIndex(mol), EState.MinEStateIndex(mol), EState.MinAbsEStateIndex(mol),\n",
        "            Descriptors.qed(mol), Descriptors.MolWt(mol), Descriptors.NumRadicalElectrons(mol),\n",
        "            rdMolDescriptors.CalcMaxPartialCharge(mol), rdMolDescriptors.CalcMinPartialCharge(mol),\n",
        "            rdMolDescriptors.CalcFractionCSP3(mol),\n",
        "            rdMolDescriptors.BCUT2D_MWHI(mol), rdMolDescriptors.BCUT2D_MWLOW(mol),\n",
        "            rdMolDescriptors.BCUT2D_CHGHI(mol), rdMolDescriptors.BCUT2D_CHGLO(mol),\n",
        "            rdMolDescriptors.BCUT2D_MRHI(mol), rdMolDescriptors.BCUT2D_MRLOW(mol),\n",
        "            GraphDescriptors.BalabanJ(mol), Descriptors.HallKierAlpha(mol), Descriptors.Kappa3(mol),\n",
        "            *rdMolDescriptors.PEOE_VSA_(mol), *rdMolDescriptors.SMR_VSA_(mol),\n",
        "            *rdMolDescriptors.SlogP_VSA_(mol), *rdMolDescriptors.EState_VSA_(mol),\n",
        "            *rdMolDescriptors.VSA_EState_(mol),\n",
        "            rdMolDescriptors.CalcFractionCSP3(mol),\n",
        "            Lipinski.NumAliphaticCarbocycles(mol), Lipinski.NumAliphaticHeterocycles(mol),\n",
        "            Lipinski.NumAliphaticRings(mol), Lipinski.NumAromaticHeterocycles(mol),\n",
        "            Descriptors.MolLogP(mol),\n",
        "            *(getattr(Fragments, name)(mol) for name in dir(Fragments) if name.startswith('fr_'))\n",
        "        ], dtype=np.float32)[:140]\n",
        "    except:\n",
        "        return np.zeros(140, dtype=np.float32)\n",
        "\n",
        "class ImprovedMolecularNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_dim, 512)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(512)\n",
        "        self.fc2 = torch.nn.Linear(512, 256)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(256)\n",
        "        self.fc3 = torch.nn.Linear(256, 128)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(128)\n",
        "        self.fc4 = torch.nn.Linear(128, 64)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(64)\n",
        "        self.fc5 = torch.nn.Linear(64, 1)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU(0.1)\n",
        "        self.dropout = torch.nn.Dropout(0.4)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn4(self.fc4(x)))\n",
        "        x = self.sigmoid(self.fc5(x))\n",
        "        return x\n",
        "\n",
        "model = ImprovedMolecularNN(140)\n",
        "model = torch.load(\"Best_MPP_ANN_model.pth\", map_location=torch.device('cpu'), weights_only=False)\n",
        "model.eval()\n",
        "\n",
        "def property_predictor(mol, threshold=0.5):\n",
        "    try:\n",
        "        features = compute_rdkit_descriptors(mol)\n",
        "        input_tensor = torch.tensor(features).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probability = torch.sigmoid(output).item()\n",
        "            return int(probability >= threshold)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "##############################\n",
        "# 2. Load Data\n",
        "##############################\n",
        "\n",
        "def load_building_blocks(path):\n",
        "    df = pd.read_csv(path)\n",
        "    return [Chem.MolFromSmiles(smi) for smi in df['smiles'] if Chem.MolFromSmiles(smi)]\n",
        "\n",
        "def load_reactions():\n",
        "    rxn_list = []\n",
        "    for entry in REAL_REACTIONS:\n",
        "        try:\n",
        "            reactant_smarts = \".\".join([Chem.MolToSmarts(mol) for mol in entry[\"reactants\"]])\n",
        "            product_smarts = Chem.MolToSmarts(entry[\"product\"])\n",
        "            rxn = rdChemReactions.ReactionFromSmarts(f\"{reactant_smarts}>>{product_smarts}\")\n",
        "            rxn.Initialize()\n",
        "            rxn.reaction_id = entry[\"reaction_id\"]\n",
        "            rxn_list.append(rxn)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading reaction {entry['reaction_id']}: {e}\")\n",
        "    return rxn_list\n",
        "\n",
        "building_block_pool = load_building_blocks(\"1_building_blocks.csv\")\n",
        "reactions = load_reactions()\n",
        "\n",
        "##############################\n",
        "# 3. MCTS\n",
        "##############################\n",
        "\n",
        "class MCTSNode:\n",
        "    def __init__(self, building_blocks, parent=None, reaction=None, product=None):\n",
        "        self.building_blocks = building_blocks\n",
        "        self.parent = parent\n",
        "        self.children = []\n",
        "        self.reaction = reaction\n",
        "        self.product = product\n",
        "        self.score = 0.0\n",
        "        self.visits = 0\n",
        "        self.is_terminal = False\n",
        "\n",
        "    def ucb1(self, exploration_constant=1.4):\n",
        "        if self.visits == 0:\n",
        "            return float('inf')\n",
        "        return (self.score / self.visits) + exploration_constant * math.sqrt(math.log(self.parent.visits + 1) / self.visits)\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, root, reactions, building_block_pool, property_predictor):\n",
        "        self.root = root\n",
        "        self.reactions = reactions\n",
        "        self.building_block_pool = building_block_pool\n",
        "        self.property_predictor = property_predictor\n",
        "        self.generated_smiles = set()\n",
        "\n",
        "    def select(self, node):\n",
        "        while node.children:\n",
        "            node = max(node.children, key=lambda n: n.ucb1())\n",
        "        return node\n",
        "\n",
        "    def expand(self, node):\n",
        "        random.shuffle(self.reactions)\n",
        "        for rxn in self.reactions:\n",
        "            try:\n",
        "                k = rxn.GetNumReactantTemplates()\n",
        "                if len(self.building_block_pool) < k:\n",
        "                    continue\n",
        "                sampled = random.sample(self.building_block_pool, k)\n",
        "                products = rxn.RunReactants(sampled)\n",
        "                for product_tuple in products:\n",
        "                    product = product_tuple[0]\n",
        "                    Chem.SanitizeMol(product)\n",
        "                    smi = Chem.MolToSmiles(product)\n",
        "                    if smi in self.generated_smiles:\n",
        "                        continue\n",
        "                    self.generated_smiles.add(smi)\n",
        "                    child = MCTSNode(sampled, parent=node, reaction=rxn, product=product)\n",
        "                    child.is_terminal = True\n",
        "                    node.children.append(child)\n",
        "                    return child\n",
        "            except:\n",
        "                continue\n",
        "        return None\n",
        "\n",
        "    def simulate(self, node):\n",
        "        if node.product is not None:\n",
        "            label = self.property_predictor(node.product)\n",
        "            node.score += label\n",
        "            node.visits += 1\n",
        "            return label\n",
        "        return 0\n",
        "\n",
        "    def backpropagate(self, node, score):\n",
        "        while node is not None:\n",
        "            node.visits += 1\n",
        "            node.score += score\n",
        "            node = node.parent\n",
        "\n",
        "    def run(self, num_iterations=10000, log_every=500):\n",
        "        for i in range(num_iterations):\n",
        "            try:\n",
        "                node = self.select(self.root)\n",
        "                child = self.expand(node)\n",
        "                if child:\n",
        "                    score = self.simulate(child)\n",
        "                    self.backpropagate(child, score)\n",
        "                else:\n",
        "                    if i % log_every == 0:\n",
        "                        print(f\"[{i}] No valid child. Total unique molecules: {len(self.generated_smiles)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[{i}] Error: {e}\")\n",
        "                continue\n",
        "            if i % log_every == 0:\n",
        "                print(f\"[{i}] Progress: {self.root.visits} visits, {len(self.root.children)} root children\")\n",
        "\n",
        "##############################\n",
        "# 4. Diversity Filter + Output + Uniqueness Check\n",
        "##############################\n",
        "\n",
        "def get_top_molecules(root, top_k=1000):\n",
        "    all_nodes = []\n",
        "    def dfs(node):\n",
        "        if node.is_terminal and node.product is not None:\n",
        "            score = node.score / max(node.visits, 1)\n",
        "            all_nodes.append((score, node))\n",
        "        for child in node.children:\n",
        "            dfs(child)\n",
        "    dfs(root)\n",
        "    all_nodes.sort(key=lambda x: -x[0])\n",
        "    return all_nodes[:top_k]\n",
        "\n",
        "def filter_diverse_molecules(scored_nodes, threshold=0.8):\n",
        "    diverse = []\n",
        "    fps = []\n",
        "    for score, node in scored_nodes:\n",
        "        fp = AllChem.GetMorganFingerprint(node.product, radius=2)\n",
        "        if all(DataStructs.TanimotoSimilarity(fp, prev_fp) < threshold for prev_fp in fps):\n",
        "            diverse.append((score, node))\n",
        "            fps.append(fp)\n",
        "    return diverse\n",
        "\n",
        "def write_unique_molecules(diverse_nodes, train_csv):\n",
        "    train_df = pd.read_csv(train_csv)\n",
        "    train_smiles = set(train_df['smiles'].dropna().unique())\n",
        "    unique_nodes = [(score, node) for score, node in diverse_nodes if Chem.MolToSmiles(node.product) not in train_smiles]\n",
        "\n",
        "    with open(\"mcts unique batch label.csv\", \"w\", newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Rank\", \"Label\", \"Product_SMILES\", \"Reaction_ID\", \"Building_Blocks\"])\n",
        "        for i, (score, node) in enumerate(unique_nodes):\n",
        "            smiles = Chem.MolToSmiles(node.product)\n",
        "            bb_smiles = [Chem.MolToSmiles(m) for m in node.building_blocks]\n",
        "            rxn_id = getattr(node.reaction, 'reaction_id', 'N/A')\n",
        "            label = int(round(score))\n",
        "            print(f\"Unique Rank {i+1}: Label = {label}, SMILES = {smiles}\")\n",
        "            writer.writerow([i + 1, label, smiles, rxn_id, \".\".join(bb_smiles)])\n",
        "    return unique_nodes  # <-- RETURN unique_nodes here!\n",
        "\n",
        "##############################\n",
        "# 5. Run MCTS\n",
        "##############################\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize_summary(unique_nodes, train_smiles):\n",
        "    gen_fps = []\n",
        "    gen_smiles = []\n",
        "    tanimoto_to_train = []\n",
        "    diversity_scores = []\n",
        "    mcts_labels = []\n",
        "    mcts_scores = []\n",
        "    reaction_ids = []\n",
        "    building_blocks_list = []\n",
        "    gen_bit_fps = []\n",
        "\n",
        "    # Precompute training molecules and fingerprints\n",
        "    train_mols = [Chem.MolFromSmiles(s) for s in train_smiles if Chem.MolFromSmiles(s)]\n",
        "    train_fps = [AllChem.GetMorganFingerprint(mol, 2) for mol in train_mols]\n",
        "    train_bit_fps = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024) for mol in train_mols]\n",
        "\n",
        "    for i, (score, node) in enumerate(unique_nodes):\n",
        "        mol = node.product\n",
        "        smi = Chem.MolToSmiles(mol)\n",
        "        fp = AllChem.GetMorganFingerprint(mol, 2)\n",
        "        bit_fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)\n",
        "\n",
        "        gen_smiles.append(smi)\n",
        "        gen_fps.append(fp)\n",
        "        gen_bit_fps.append(bit_fp)\n",
        "        mcts_labels.append(int(round(score)))\n",
        "        mcts_scores.append(score)\n",
        "\n",
        "        # Reaction ID and Building Blocks\n",
        "        rxn_id = getattr(node.reaction, 'reaction_id', 'N/A')\n",
        "        bb_smiles = \".\".join([Chem.MolToSmiles(m) for m in node.building_blocks])\n",
        "        reaction_ids.append(rxn_id)\n",
        "        building_blocks_list.append(bb_smiles)\n",
        "\n",
        "        # Tanimoto to training set\n",
        "        max_sim_train = max(DataStructs.TanimotoSimilarity(fp, tfp) for tfp in train_fps)\n",
        "        tanimoto_to_train.append(max_sim_train)\n",
        "\n",
        "        # Diversity score (1 - max similarity to previous)\n",
        "        if i == 0:\n",
        "            diversity_scores.append(1.0)\n",
        "        else:\n",
        "            max_sim_prev = max(DataStructs.TanimotoSimilarity(fp, prev_fp) for prev_fp in gen_fps[:i])\n",
        "            diversity_scores.append(1.0 - max_sim_prev)\n",
        "\n",
        "    # Plot histogram of Tanimoto similarity to training\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(tanimoto_to_train, bins=20, color='green', edgecolor='black')\n",
        "    plt.title(\"Max Tanimoto Similarity to Training Set\")\n",
        "    plt.xlabel(\"Tanimoto Similarity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"similarity_distribution.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Save all scores and metadata to CSV\n",
        "    df = pd.DataFrame({\n",
        "        'rank': list(range(1, len(gen_smiles) + 1)),\n",
        "        'generated_smiles': gen_smiles,\n",
        "        'tanimoto_to_train': tanimoto_to_train,\n",
        "        'diversity_score': diversity_scores,\n",
        "        'mcts_label': mcts_labels,\n",
        "        'mcts_score': mcts_scores,\n",
        "        'reaction_id': reaction_ids,\n",
        "        'building_blocks': building_blocks_list\n",
        "    })\n",
        "    df.to_csv(\"generated_molecule_scores.csv\", index=False)\n",
        "    print(\" Saved summary: generated_molecule_scores.csv\")\n",
        "\n",
        "    # ========================\n",
        "    # t-SNE Visualization\n",
        "    # ========================\n",
        "    gen_arr = [np.array(list(fp.ToBitString()), dtype=int) for fp in gen_bit_fps]\n",
        "    train_arr = [np.array(list(fp.ToBitString()), dtype=int) for fp in train_bit_fps]\n",
        "\n",
        "    all_arr = gen_arr + train_arr\n",
        "    all_arr_np = np.array(all_arr)\n",
        "\n",
        "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "    tsne_result = tsne.fit_transform(all_arr_np)\n",
        "\n",
        "    gen_tsne = tsne_result[:len(gen_arr)]\n",
        "    train_tsne = tsne_result[len(gen_arr):]\n",
        "\n",
        "    # Plot t-SNE\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(train_tsne[:, 0], train_tsne[:, 1], c='gray', label='Training', alpha=0.5)\n",
        "    plt.scatter(gen_tsne[:, 0], gen_tsne[:, 1], c='blue', label='Generated', alpha=0.7)\n",
        "    plt.title(\"t-SNE of Morgan Fingerprints\")\n",
        "    plt.xlabel(\"t-SNE 1\")\n",
        "    plt.ylabel(\"t-SNE 2\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"tsne_plot.png\")\n",
        "    plt.show()\n",
        "    print(\" Saved t-SNE plot: tsne_plot.png\")\n",
        "\n",
        "# Load training SMILES and run visualization\n",
        "train_df = pd.read_csv(\"1-unique_clean_smiles.csv\")\n",
        "train_smiles = train_df['smiles'].dropna().unique()\n",
        "visualize_summary(unique_nodes, train_smiles)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7TT4GsZ_Os3x",
        "MvzRTTOFOykH",
        "cxE8-Tc8O8O7",
        "kn39PE1jPEew",
        "ma73mFZkVPSV"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
